<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Class NGramTokenizer
 | Apache Lucene.NET 4.8.0-beta00017 Documentation </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Class NGramTokenizer
 | Apache Lucene.NET 4.8.0-beta00017 Documentation ">
    <meta name="generator" content="docfx ">
  
    <link rel="shortcut icon" href="https://lucenenet.apache.org/docs/4.8.0-beta00017/logo/favicon.ico">
    <link rel="stylesheet" href="https://lucenenet.apache.org/docs/4.8.0-beta00017/styles/docfx.vendor.min.css">
    <link rel="stylesheet" href="https://lucenenet.apache.org/docs/4.8.0-beta00017/styles/docfx.css">
    <link rel="stylesheet" href="https://lucenenet.apache.org/docs/4.8.0-beta00017/styles/main.css">
    <meta property="docfx:navrel" content="toc.html">
    <meta property="docfx:tocrel" content="analysis-common/toc.html">
  
  <meta property="docfx:rel" content="https://lucenenet.apache.org/docs/4.8.0-beta00017/">
  
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <span id="forkongithub"><a href="https://github.com/apache/lucenenet" target="_blank">Fork me on GitHub</a></span>
    <div id="wrapper">
      <header>

        <nav id="autocollapse" class="navbar ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>

              <a class="navbar-brand" href="/">
                <img id="logo" class="svg" src="https://lucenenet.apache.org/docs/4.8.0-beta00017/logo/lucene-net-color.png" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>

        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search">
            <ul class="level0 breadcrumb">
                <li>
                    <a href="https://lucenenet.apache.org/docs/4.8.0-beta00017/">API</a>
                     <span id="breadcrumb">
                        <ul class="breadcrumb">
                          <li></li>
                        </ul>
                    </span>   
                </li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">

        <div id="search-results">
          <div class="search-list"></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">

        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer">


  <h1 id="Lucene_Net_Analysis_NGram_NGramTokenizer" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer" class="text-break">Class NGramTokenizer
</h1>
  <div class="markdown level0 summary"><p>Tokenizes the input into n-grams of the given size(s).</p>
<p>On the contrary to <a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenFilter.html">NGramTokenFilter</a>, this class sets offsets so
that characters between startOffset and endOffset in the original stream are
the same as the term chars.
</p><p>For example, "abcde" would be tokenized as (minGram=2, maxGram=3):
<table><thead><tr><th class="term">Term</th><th class="term">Position increment</th><th class="term">Position length</th><th class="term">Offsets</th></tr></thead><tbody><tr><td class="term">ab</td><td class="term">1</td><td class="term">1</td><td class="term">[0,2[</td></tr><tr><td class="term">abc</td><td class="term">1</td><td class="term">1</td><td class="term">[0,3[</td></tr><tr><td class="term">bc</td><td class="term">1</td><td class="term">1</td><td class="term">[1,3[</td></tr><tr><td class="term">bcd</td><td class="term">1</td><td class="term">1</td><td class="term">[1,4[</td></tr><tr><td class="term">cd</td><td class="term">1</td><td class="term">1</td><td class="term">[2,4[</td></tr><tr><td class="term">cde</td><td class="term">1</td><td class="term">1</td><td class="term">[2,5[</td></tr><tr><td class="term">de</td><td class="term">1</td><td class="term">1</td><td class="term">[3,5[</td></tr></tbody></table><p>This tokenizer changed a lot in Lucene 4.4 in order to:
<ul><li>tokenize in a streaming fashion to support streams which are larger
        than 1024 chars (limit of the previous version),</li><li>count grams based on unicode code points instead of java chars (and
        never split in the middle of surrogate pairs),</li><li>give the ability to pre-tokenize the stream (<a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenizer.html#Lucene_Net_Analysis_NGram_NGramTokenizer_IsTokenChar_System_Int32_">IsTokenChar(int)</a>)
        before computing n-grams.</li></ul><p>Additionally, this class doesn't trim trailing whitespaces and emits
tokens in a different order, tokens are now emitted by increasing start
offsets while they used to be emitted by increasing lengths (which prevented
from supporting large input streams).
</p><p>Although <b style="color:red">highly</b> discouraged, it is still possible
to use the old behavior through <a class="xref" href="Lucene.Net.Analysis.NGram.Lucene43NGramTokenizer.html">Lucene43NGramTokenizer</a>.
</p>
</div>
  <div class="markdown level0 conceptual"></div>
  <div class="inheritance">
    <h5>Inheritance</h5>
    <div class="level0"><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
    <div class="level1"><span class="xref">AttributeSource</span></div>
    <div class="level2"><span class="xref">TokenStream</span></div>
    <div class="level3"><span class="xref">Tokenizer</span></div>
    <div class="level4"><span class="xref">NGramTokenizer</span></div>
      <div class="level5"><a class="xref" href="Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.html">EdgeNGramTokenizer</a></div>
  </div>
  <div classs="implements">
    <h5>Implements</h5>
    <div><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a></div>
  </div>
  <div class="inheritedMembers">
    <h5>Inherited Members</h5>
    <div>
      <span class="xref">Tokenizer.m_input</span>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">Tokenizer.Dispose(bool)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">Tokenizer.CorrectOffset(int)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">Tokenizer.SetReader(TextReader)</a>
    </div>
    <div>
      <span class="xref">TokenStream.Dispose()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.GetAttributeFactory()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.GetAttributeClassesEnumerator()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.GetAttributeImplsEnumerator()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.AddAttributeImpl(Attribute)</span>
    </div>
    <div>
      <span class="xref">AttributeSource.AddAttribute&lt;T&gt;()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.HasAttributes</span>
    </div>
    <div>
      <span class="xref">AttributeSource.HasAttribute&lt;T&gt;()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.GetAttribute&lt;T&gt;()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.ClearAttributes()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.CaptureState()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.RestoreState(AttributeSource.State)</span>
    </div>
    <div>
      <span class="xref">AttributeSource.GetHashCode()</span>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">AttributeSource.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">AttributeSource.ReflectAsString(bool)</a>
    </div>
    <div>
      <span class="xref">AttributeSource.ReflectWith(IAttributeReflector)</span>
    </div>
    <div>
      <span class="xref">AttributeSource.CloneAttributes()</span>
    </div>
    <div>
      <span class="xref">AttributeSource.CopyTo(AttributeSource)</span>
    </div>
    <div>
      <span class="xref">AttributeSource.ToString()</span>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
  </div>
  <h6><strong>Namespace</strong>: <a class="xref" href="Lucene.html">Lucene</a>.<a class="xref" href="Lucene.Net.html">Net</a>.<a class="xref" href="Lucene.Net.Analysis.html">Analysis</a>.<a class="xref" href="Lucene.Net.Analysis.NGram.html">NGram</a></h6>
  <h6><strong>Assembly</strong>: Lucene.Net.Analysis.Common.dll</h6>
  <h5 id="Lucene_Net_Analysis_NGram_NGramTokenizer_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public class NGramTokenizer : Tokenizer, IDisposable</code></pre>
  </div>
  <h3 id="constructors">Constructors
</h3>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer__ctor_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer__ctor_Lucene_Net_Util_LuceneVersion_Lucene_Net_Util_AttributeSource_AttributeFactory_System_IO_TextReader_System_Int32_System_Int32_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(Lucene.Net.Util.LuceneVersion,Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader,System.Int32,System.Int32)">NGramTokenizer(LuceneVersion, AttributeFactory, TextReader, int, int)</h4>
  <div class="markdown level1 summary"><p>Creates <a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenizer.html">NGramTokenizer</a> with given min and max n-grams.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public NGramTokenizer(LuceneVersion version, AttributeSource.AttributeFactory factory, TextReader input, int minGram, int maxGram)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">LuceneVersion</span></td>
        <td><span class="parametername">version</span></td>
        <td><p>the lucene compatibility version</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">AttributeSource</span>.<span class="xref">AttributeFactory</span></td>
        <td><span class="parametername">factory</span></td>
        <td><p><span class="xref">Lucene.Net.Util.AttributeSource.AttributeFactory</span> to use</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">TextReader</a></td>
        <td><span class="parametername">input</span></td>
        <td><p><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">TextReader</a> holding the input to be tokenized</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td><span class="parametername">minGram</span></td>
        <td><p>the smallest n-gram to generate</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td><span class="parametername">maxGram</span></td>
        <td><p>the largest n-gram to generate</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer__ctor_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer__ctor_Lucene_Net_Util_LuceneVersion_System_IO_TextReader_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(Lucene.Net.Util.LuceneVersion,System.IO.TextReader)">NGramTokenizer(LuceneVersion, TextReader)</h4>
  <div class="markdown level1 summary"><p>Creates <a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenizer.html">NGramTokenizer</a> with default min and max n-grams.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public NGramTokenizer(LuceneVersion version, TextReader input)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">LuceneVersion</span></td>
        <td><span class="parametername">version</span></td>
        <td><p>the lucene compatibility version</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">TextReader</a></td>
        <td><span class="parametername">input</span></td>
        <td><p><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">TextReader</a> holding the input to be tokenized</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer__ctor_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer__ctor_Lucene_Net_Util_LuceneVersion_System_IO_TextReader_System_Int32_System_Int32_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(Lucene.Net.Util.LuceneVersion,System.IO.TextReader,System.Int32,System.Int32)">NGramTokenizer(LuceneVersion, TextReader, int, int)</h4>
  <div class="markdown level1 summary"><p>Creates <a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenizer.html">NGramTokenizer</a> with given min and max n-grams.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public NGramTokenizer(LuceneVersion version, TextReader input, int minGram, int maxGram)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">LuceneVersion</span></td>
        <td><span class="parametername">version</span></td>
        <td><p>the lucene compatibility version</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">TextReader</a></td>
        <td><span class="parametername">input</span></td>
        <td><p><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.textreader">TextReader</a> holding the input to be tokenized</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td><span class="parametername">minGram</span></td>
        <td><p>the smallest n-gram to generate</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td><span class="parametername">maxGram</span></td>
        <td><p>the largest n-gram to generate</p>
</td>
      </tr>
    </tbody>
  </table>
  <h3 id="fields">Fields
</h3>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer_DEFAULT_MAX_NGRAM_SIZE" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.DEFAULT_MAX_NGRAM_SIZE">DEFAULT_MAX_NGRAM_SIZE</h4>
  <div class="markdown level1 summary"><p>Tokenizes the input into n-grams of the given size(s).</p>
<p>On the contrary to <a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenFilter.html">NGramTokenFilter</a>, this class sets offsets so
that characters between startOffset and endOffset in the original stream are
the same as the term chars.
</p><p>For example, "abcde" would be tokenized as (minGram=2, maxGram=3):
<table><thead><tr><th class="term">Term</th><th class="term">Position increment</th><th class="term">Position length</th><th class="term">Offsets</th></tr></thead><tbody><tr><td class="term">ab</td><td class="term">1</td><td class="term">1</td><td class="term">[0,2[</td></tr><tr><td class="term">abc</td><td class="term">1</td><td class="term">1</td><td class="term">[0,3[</td></tr><tr><td class="term">bc</td><td class="term">1</td><td class="term">1</td><td class="term">[1,3[</td></tr><tr><td class="term">bcd</td><td class="term">1</td><td class="term">1</td><td class="term">[1,4[</td></tr><tr><td class="term">cd</td><td class="term">1</td><td class="term">1</td><td class="term">[2,4[</td></tr><tr><td class="term">cde</td><td class="term">1</td><td class="term">1</td><td class="term">[2,5[</td></tr><tr><td class="term">de</td><td class="term">1</td><td class="term">1</td><td class="term">[3,5[</td></tr></tbody></table><p>This tokenizer changed a lot in Lucene 4.4 in order to:
<ul><li>tokenize in a streaming fashion to support streams which are larger
        than 1024 chars (limit of the previous version),</li><li>count grams based on unicode code points instead of java chars (and
        never split in the middle of surrogate pairs),</li><li>give the ability to pre-tokenize the stream (<a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenizer.html#Lucene_Net_Analysis_NGram_NGramTokenizer_IsTokenChar_System_Int32_">IsTokenChar(int)</a>)
        before computing n-grams.</li></ul><p>Additionally, this class doesn't trim trailing whitespaces and emits
tokens in a different order, tokens are now emitted by increasing start
offsets while they used to be emitted by increasing lengths (which prevented
from supporting large input streams).
</p><p>Although <b style="color:red">highly</b> discouraged, it is still possible
to use the old behavior through <a class="xref" href="Lucene.Net.Analysis.NGram.Lucene43NGramTokenizer.html">Lucene43NGramTokenizer</a>.
</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public const int DEFAULT_MAX_NGRAM_SIZE = 2</code></pre>
  </div>
  <h5 class="fieldValue">Field Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer_DEFAULT_MIN_NGRAM_SIZE" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.DEFAULT_MIN_NGRAM_SIZE">DEFAULT_MIN_NGRAM_SIZE</h4>
  <div class="markdown level1 summary"><p>Tokenizes the input into n-grams of the given size(s).</p>
<p>On the contrary to <a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenFilter.html">NGramTokenFilter</a>, this class sets offsets so
that characters between startOffset and endOffset in the original stream are
the same as the term chars.
</p><p>For example, "abcde" would be tokenized as (minGram=2, maxGram=3):
<table><thead><tr><th class="term">Term</th><th class="term">Position increment</th><th class="term">Position length</th><th class="term">Offsets</th></tr></thead><tbody><tr><td class="term">ab</td><td class="term">1</td><td class="term">1</td><td class="term">[0,2[</td></tr><tr><td class="term">abc</td><td class="term">1</td><td class="term">1</td><td class="term">[0,3[</td></tr><tr><td class="term">bc</td><td class="term">1</td><td class="term">1</td><td class="term">[1,3[</td></tr><tr><td class="term">bcd</td><td class="term">1</td><td class="term">1</td><td class="term">[1,4[</td></tr><tr><td class="term">cd</td><td class="term">1</td><td class="term">1</td><td class="term">[2,4[</td></tr><tr><td class="term">cde</td><td class="term">1</td><td class="term">1</td><td class="term">[2,5[</td></tr><tr><td class="term">de</td><td class="term">1</td><td class="term">1</td><td class="term">[3,5[</td></tr></tbody></table><p>This tokenizer changed a lot in Lucene 4.4 in order to:
<ul><li>tokenize in a streaming fashion to support streams which are larger
        than 1024 chars (limit of the previous version),</li><li>count grams based on unicode code points instead of java chars (and
        never split in the middle of surrogate pairs),</li><li>give the ability to pre-tokenize the stream (<a class="xref" href="Lucene.Net.Analysis.NGram.NGramTokenizer.html#Lucene_Net_Analysis_NGram_NGramTokenizer_IsTokenChar_System_Int32_">IsTokenChar(int)</a>)
        before computing n-grams.</li></ul><p>Additionally, this class doesn't trim trailing whitespaces and emits
tokens in a different order, tokens are now emitted by increasing start
offsets while they used to be emitted by increasing lengths (which prevented
from supporting large input streams).
</p><p>Although <b style="color:red">highly</b> discouraged, it is still possible
to use the old behavior through <a class="xref" href="Lucene.Net.Analysis.NGram.Lucene43NGramTokenizer.html">Lucene43NGramTokenizer</a>.
</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public const int DEFAULT_MIN_NGRAM_SIZE = 1</code></pre>
  </div>
  <h5 class="fieldValue">Field Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="methods">Methods
</h3>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer_End_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.End*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer_End" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.End">End()</h4>
  <div class="markdown level1 summary"><p>This method is called by the consumer after the last token has been
consumed, after <span class="xref">Lucene.Net.Analysis.TokenStream.IncrementToken()</span> returned <code>false</code>
(using the new <span class="xref">Lucene.Net.Analysis.TokenStream</span> API). Streams implementing the old API
should upgrade to use this feature.</p>
<p></p>
This method can be used to perform any end-of-stream operations, such as
setting the final offset of a stream. The final offset of a stream might
differ from the offset of the last token eg in case one or more whitespaces
followed after the last token, but a WhitespaceTokenizer was used.
<p></p>
Additionally any skipped positions (such as those removed by a stopfilter)
can be applied to the position increment, or any adjustment of other
attributes where the end-of-stream value may be important.
<p></p>
If you override this method, always call <code>base.End();</code>.
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public override sealed void End()</code></pre>
  </div>
  <h5 class="overrides">Overrides</h5>
  <div><span class="xref">Lucene.Net.Analysis.TokenStream.End()</span></div>
  <h5 class="exceptions">Exceptions</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Condition</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.io.ioexception">IOException</a></td>
        <td><p>If an I/O error occurs</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer_IncrementToken_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.IncrementToken*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer_IncrementToken" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.IncrementToken">IncrementToken()</h4>
  <div class="markdown level1 summary"><p>Consumers (i.e., <span class="xref">Lucene.Net.Index.IndexWriter</span>) use this method to advance the stream to
the next token. Implementing classes must implement this method and update
the appropriate <span class="xref">Lucene.Net.Util.IAttribute</span>s with the attributes of the next
token.</p>
<p></p>
The producer must make no assumptions about the attributes after the method
has been returned: the caller may arbitrarily change it. If the producer
needs to preserve the state for subsequent calls, it can use
<span class="xref">Lucene.Net.Util.AttributeSource.CaptureState()</span> to create a copy of the current attribute state.
<p></p>
this method is called for every token of a document, so an efficient
implementation is crucial for good performance. To avoid calls to
<span class="xref">Lucene.Net.Util.AttributeSource.AddAttribute&lt;T&gt;()</span> and <span class="xref">Lucene.Net.Util.AttributeSource.GetAttribute&lt;T&gt;()</span>,
references to all <span class="xref">Lucene.Net.Util.IAttribute</span>s that this stream uses should be
retrieved during instantiation.
<p></p>
To ensure that filters and consumers know which attributes are available,
the attributes must be added during instantiation. Filters and consumers
are not required to check for availability of attributes in
<span class="xref">Lucene.Net.Analysis.TokenStream.IncrementToken()</span>.
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public override sealed bool IncrementToken()</code></pre>
  </div>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></td>
        <td><p>false for end of stream; true otherwise</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="overrides">Overrides</h5>
  <div><span class="xref">Lucene.Net.Analysis.TokenStream.IncrementToken()</span></div>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer_IsTokenChar_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.IsTokenChar*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer_IsTokenChar_System_Int32_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.IsTokenChar(System.Int32)">IsTokenChar(int)</h4>
  <div class="markdown level1 summary"><p>Only collect characters which satisfy this condition.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">protected virtual bool IsTokenChar(int chr)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td><span class="parametername">chr</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="Lucene_Net_Analysis_NGram_NGramTokenizer_Reset_" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.Reset*"></a>
  <h4 id="Lucene_Net_Analysis_NGram_NGramTokenizer_Reset" data-uid="Lucene.Net.Analysis.NGram.NGramTokenizer.Reset">Reset()</h4>
  <div class="markdown level1 summary"><p>This method is called by a consumer before it begins consumption using
<span class="xref">Lucene.Net.Analysis.TokenStream.IncrementToken()</span>.</p>
<p></p>
Resets this stream to a clean state. Stateful implementations must implement
this method so that they can be reused, just as if they had been created fresh.
<p></p>
If you override this method, always call <code>base.Reset()</code>, otherwise
some internal state will not be correctly reset (e.g., <span class="xref">Lucene.Net.Analysis.Tokenizer</span> will
throw <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a> on further usage).
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang- hljs">public override sealed void Reset()</code></pre>
  </div>
  <h5 class="overrides">Overrides</h5>
  <div><span class="xref">Lucene.Net.Analysis.Tokenizer.Reset()</span></div>
  <h3 id="implements">Implements</h3>
  <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.idisposable">IDisposable</a>
  </div>
</article>
          </div>

          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>

      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
      Copyright &copy; 2024 The Apache Software Foundation, Licensed under the <a href='http://www.apache.org/licenses/LICENSE-2.0' target='_blank'>Apache License, Version 2.0</a><br> <small>Apache Lucene.Net, Lucene.Net, Apache, the Apache feather logo, and the Apache Lucene.Net project logo are trademarks of The Apache Software Foundation. <br>All other marks mentioned may be trademarks or registered trademarks of their respective owners.</small>
      
          </div>
        </div>
      </footer>
    </div>

    <script type="text/javascript" src="https://lucenenet.apache.org/docs/4.8.0-beta00017/styles/docfx.vendor.min.js"></script>
    <script type="text/javascript" src="https://lucenenet.apache.org/docs/4.8.0-beta00017/styles/docfx.js"></script>
    <script type="text/javascript" src="https://lucenenet.apache.org/docs/4.8.0-beta00017/styles/main.js"></script>
  </body>
</html>
